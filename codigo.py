# =========================================================
#  Modelo H√≠brido Final: Regresi√≥n Lineal + Random Forest
#  An√°lisis Saber Pro 2018‚Äì2022
# =========================================================

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns

# =========================================================
# Cargar los datos
# =========================================================
data = pd.read_csv(
    r"resultados.csv",
    encoding='latin-1',
    sep=',',
    low_memory=False
)
print("‚úÖ Archivo cargado correctamente")
print(f"üîπ Dimensiones iniciales: {data.shape[0]} filas y {data.shape[1]} columnas\n")


# =========================================================
# Variables socioecon√≥micas seleccionadas
# =========================================================
features = [
    # üè† Socioecon√≥micas
    'FAMI_ESTRATOVIVIENDA', 'FAMI_EDUCACIONPADRE', 'FAMI_EDUCACIONMADRE',
    'FAMI_TIENECOMPUTADOR', 'FAMI_TIENEINTERNET', 'FAMI_TIENEAUTOMOVIL', 'FAMI_TIENELAVADORA',

    # üéì Acad√©micas
    'ESTU_NIVEL_PRGM_ACADEMICO', 'ESTU_METODO_PRGM',
    'ESTU_HORASSEMANATRABAJA', 'ESTU_ESTADOINVESTIGACION',

    # üí∞ Financieras
    'ESTU_PAGOMATRICULABECA', 'ESTU_PAGOMATRICULACREDITO',
    'ESTU_PAGOMATRICULAPADRES', 'ESTU_PAGOMATRICULAPROPIO',

    # üè´ Institucionales / Geogr√°ficas
    'INST_CARACTER_ACADEMICO', 'INST_ORIGEN',
    'ESTU_DEPTO_PRESENTACION', 'ESTU_MCPIO_PRESENTACION',

    # üë©‚Äçüéì Demogr√°ficas
    'ESTU_GENERO', 'ESTU_NACIONALIDAD',
    'ESTU_PRIVADO_LIBERTAD', 'ESTU_NUCLEO_PREGRADO',

    # üåé Contextuales
    'PERIODO', 'MOD_RAZONA_CUANTITAT_PUNT'
]

# =========================================================
# Variable objetivo
# =========================================================
data['PUNTAJE_PROMEDIO'] = data[[
    'MOD_RAZONA_CUANTITAT_PUNT',
    'MOD_LECTURA_CRITICA_PUNT',
    'MOD_COMUNI_ESCRITA_PUNT',
    'MOD_INGLES_PUNT',
    'MOD_COMPETEN_CIUDADA_PUNT'
]].mean(axis=1)
target = 'PUNTAJE_PROMEDIO'

# =========================================================
# LIMPIEZA DE DATOS
# =========================================================
print(" Iniciando limpieza de datos...")

data = data.drop_duplicates()

# Normalizar texto
for col in data.select_dtypes(include=['object']).columns:
    data[col] = data[col].astype(str).str.strip().str.upper()

# Eliminar columnas con m√°s del 90 % de nulos
cols_to_drop = data.columns[data.isnull().mean() > 0.9].tolist()
data = data.drop(columns=cols_to_drop)
print(f"üóëÔ∏è Columnas eliminadas (>90 % nulos): {cols_to_drop}")

# Rellenar nulos
for col in data.columns:
    if data[col].dtype == 'object':
        data[col] = data[col].fillna('DESCONOCIDO')
    else:
        data[col] = data[col].fillna(0)

print(f" Dimensiones despu√©s de limpieza: {data.shape}\n")

# =========================================================
# Codificaci√≥n de variables categ√≥ricas
# =========================================================
le = LabelEncoder()
for col in features:
    if data[col].dtype == 'object':
        data[col] = le.fit_transform(data[col])

# =========================================================
# Divisi√≥n de datos
# =========================================================
data = data.sample(frac=0.3, random_state=42)
X = data[features]
y = data[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# =========================================================
# MODELO H√çBRIDO: Regresi√≥n Lineal + Random Forest
# =========================================================
# Entrenar la parte lineal
lr = LinearRegression()
lr.fit(X_train, y_train)
pred_lineal = lr.predict(X_train)

# Calcular residuos
residuos_train = y_train - pred_lineal

# Entrenar el Random Forest para los residuos
rf = RandomForestRegressor(
    n_estimators=120,
    max_depth=18,
    min_samples_split=4,
    min_samples_leaf=2,
    max_features='sqrt',
    random_state=42,
    n_jobs=-1
)
rf.fit(X_train, residuos_train)

# Predicci√≥n final combinada
pred_lineal_test = lr.predict(X_test)
correccion_rf = rf.predict(X_test)
y_pred_final = pred_lineal_test + correccion_rf

# =========================================================
# Evaluaci√≥n final del modelo h√≠brido
# =========================================================
r2 = r2_score(y_test, y_pred_final)
mae = mean_absolute_error(y_test, y_pred_final)
rmse = np.sqrt(mean_squared_error(y_test, y_pred_final))
precision = r2 * 100  # porcentaje de predicci√≥n

print("üìà Resultados del Modelo H√≠brido Final:")
print(f"Coeficiente de determinaci√≥n (R¬≤): {r2:.3f}")
print(f"Error absoluto medio (MAE): {mae:.3f}")
print(f"Ra√≠z del error cuadr√°tico medio (RMSE): {rmse:.3f}")
print(f" Porcentaje de predicci√≥n del modelo: {precision:.2f}%\n")

# =========================================================
# An√°lisis de Coeficientes e Importancia
# =========================================================
coef_df = pd.DataFrame({
    'Variable': features,
    'Coeficiente (Lineal)': lr.coef_
}).sort_values(by='Coeficiente (Lineal)', ascending=False)

importancias = pd.DataFrame({
    'Variable': features,
    'Importancia (No lineal)': rf.feature_importances_
}).sort_values(by='Importancia (No lineal)', ascending=False)

print("Coeficientes (parte lineal):\n", coef_df)
print("\nImportancia (parte no lineal):\n", importancias)

# =========================================================
# MATRIZ DE CORRELACI√ìN
# =========================================================
corr = data[features + [target]].corr()
plt.figure("Matriz de correlaci√≥n", figsize=(10, 6))
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Matriz de correlaci√≥n - Variables socioecon√≥micas y puntaje Saber Pro")
plt.tight_layout()

# =========================================================
# GR√ÅFICA REAL VS PREDICHO
# =========================================================
plt.figure("Predicci√≥n vs Real", figsize=(7, 7))
plt.scatter(y_test, y_pred_final, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.title("Comparaci√≥n entre valores reales y predichos (Modelo H√≠brido)")
plt.xlabel("Valores reales")
plt.ylabel("Valores predichos")
plt.grid(True)
plt.tight_layout()

# =========================================================
# GR√ÅFICAS ADICIONALES
# =========================================================
plt.figure("Coeficientes Lineales", figsize=(8, 5))
plt.barh(coef_df['Variable'], coef_df['Coeficiente (Lineal)'])
plt.title("Coeficientes - Parte Lineal del Modelo")
plt.xlabel("Coeficiente")
plt.tight_layout()

plt.figure("Importancia No Lineal", figsize=(8, 5))
plt.barh(importancias['Variable'], importancias['Importancia (No lineal)'])
plt.title("Importancia - Parte No Lineal (Random Forest)")
plt.xlabel("Importancia")
plt.tight_layout()

plt.figure("Distribuci√≥n Puntaje", figsize=(8, 5))
plt.hist(data['PUNTAJE_PROMEDIO'], bins=30)
plt.title("Distribuci√≥n del Puntaje Promedio Saber Pro")
plt.xlabel("Puntaje promedio")
plt.ylabel("N√∫mero de estudiantes")
plt.tight_layout()

plt.show()
